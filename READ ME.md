# Aisling Data Cleaning & Import Automation

This Python script automates the entire data cleaning and import pipeline for the Aisling Bookstore weekly data feed.

## âœ… Features

- Cleans five input CSV tables: `buyers`, `products`, `reviews`, `sellers`, `transactions`
- Handles:
  - Missing values
  - Duplicates
  - Type casting
  - Business logic (age ranges, discounts, etc.)
- Cross-field consistency checks (`book_id`, `seller_id`, `buyer_id`)
- Automatically disables and re-enables PostgreSQL constraints for safe import
- Exports to PostgreSQL using `psycopg2` and `copy_expert`
- Archives input files with timestamp
- Logs every deletion/modification to `deleted_data_logs.txt`

## ðŸ“‚ Folder Structure

```
aisling_script/
â”œâ”€â”€ aisling_input_data/
â”‚   â”œâ”€â”€ buyers.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ aisling_output_data/
â”‚   â””â”€â”€ buyers_YYYYMMDD_HHMMSS.csv
â”œâ”€â”€ asiling_script.py
â”œâ”€â”€ deleted_data_logs.txt
```

## ðŸš€ How to Use

1. Place your cleaned input CSVs into the `aisling_input_data/` folder.
2. Make sure the structure matches the original template.
3. Run the script:
```bash
python asiling_script.py
```
4. The cleaned data will be:
   - Inserted into your PostgreSQL `AISLING (Book Store)` database
   - Logged to `deleted_data_logs.txt`
   - Archived in `aisling_output_data/`

## ðŸ›‘ Important Notes

- Do not change the structure of the input CSVs without notice
- All missing, duplicated, or invalid entries are logged
- The script **truncates** PostgreSQL tables before re-inserting data
- PostgreSQL credentials must be correct in the script

## ðŸ“¦ Dependencies

- `pandas`
- `psycopg2`
- `dateutil`
